{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = make_classification(n_samples=100,n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "x_test, y_test = make_classification(n_samples=20,n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(2, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.676867663860321\n",
      "Validation loss decreased (0.000000 ===> 0.676868). Saving the model...\n",
      "Epoch 1: train loss: 0.7275660037994385\n",
      "Validation loss decreased (0.676868 ===> 0.727566). Saving the model...\n",
      "Epoch 2: train loss: 0.7030876874923706\n",
      "Epoch 3: train loss: 0.6865057945251465\n",
      "Epoch 4: train loss: 0.6829796433448792\n",
      "Epoch 5: train loss: 0.7099164724349976\n",
      "Epoch 6: train loss: 0.6801297664642334\n",
      "Epoch 7: train loss: 0.6966327428817749\n",
      "Epoch 8: train loss: 0.7026124596595764\n",
      "Epoch 9: train loss: 0.688598096370697\n",
      "Epoch 10: train loss: 0.6839354634284973\n",
      "Epoch 11: train loss: 0.6855760216712952\n",
      "Epoch 12: train loss: 0.6786801815032959\n",
      "Epoch 13: train loss: 0.6850563287734985\n",
      "Epoch 14: train loss: 0.6884932518005371\n",
      "Epoch 15: train loss: 0.6894572377204895\n",
      "Epoch 16: train loss: 0.6757038831710815\n",
      "Epoch 17: train loss: 0.6946424245834351\n",
      "Epoch 18: train loss: 0.6738321185112\n",
      "Epoch 19: train loss: 0.6818403005599976\n",
      "Epoch 20: train loss: 0.6594200134277344\n",
      "Epoch 21: train loss: 0.6634758710861206\n",
      "Epoch 22: train loss: 0.6743330359458923\n",
      "Epoch 23: train loss: 0.6880659461021423\n",
      "Epoch 24: train loss: 0.6509157419204712\n",
      "Epoch 25: train loss: 0.6830060482025146\n",
      "Epoch 26: train loss: 0.6571708917617798\n",
      "Epoch 27: train loss: 0.6756104826927185\n",
      "Epoch 28: train loss: 0.6633172631263733\n",
      "Epoch 29: train loss: 0.6628794074058533\n",
      "Epoch 30: train loss: 0.6608191132545471\n",
      "Epoch 31: train loss: 0.6730142831802368\n",
      "Epoch 32: train loss: 0.6650794148445129\n",
      "Epoch 33: train loss: 0.6559522151947021\n",
      "Epoch 34: train loss: 0.6369187831878662\n",
      "Epoch 35: train loss: 0.6478077173233032\n",
      "Epoch 36: train loss: 0.6580141186714172\n",
      "Epoch 37: train loss: 0.6607581377029419\n",
      "Epoch 38: train loss: 0.6513376832008362\n",
      "Epoch 39: train loss: 0.6392317414283752\n",
      "Epoch 40: train loss: 0.6486564874649048\n",
      "Epoch 41: train loss: 0.6367582678794861\n",
      "Epoch 42: train loss: 0.6494944095611572\n",
      "Epoch 43: train loss: 0.6643049716949463\n",
      "Epoch 44: train loss: 0.6637110710144043\n",
      "Epoch 45: train loss: 0.6555386185646057\n",
      "Epoch 46: train loss: 0.6447675228118896\n",
      "Epoch 47: train loss: 0.6455833911895752\n",
      "Epoch 48: train loss: 0.6309481859207153\n",
      "Epoch 49: train loss: 0.6448288559913635\n",
      "Epoch 50: train loss: 0.6366540789604187\n",
      "Epoch 51: train loss: 0.6259337067604065\n",
      "Epoch 52: train loss: 0.6307309865951538\n",
      "Epoch 53: train loss: 0.6361395120620728\n",
      "Epoch 54: train loss: 0.6249311566352844\n",
      "Epoch 55: train loss: 0.6253090500831604\n",
      "Epoch 56: train loss: 0.6226121783256531\n",
      "Epoch 57: train loss: 0.6187782287597656\n",
      "Epoch 58: train loss: 0.6377824544906616\n",
      "Epoch 59: train loss: 0.636563777923584\n",
      "Epoch 60: train loss: 0.6366543769836426\n",
      "Epoch 61: train loss: 0.6268473863601685\n",
      "Epoch 62: train loss: 0.6244475245475769\n",
      "Epoch 63: train loss: 0.624744713306427\n",
      "Epoch 64: train loss: 0.618007481098175\n",
      "Epoch 65: train loss: 0.6197424530982971\n",
      "Epoch 66: train loss: 0.6191853880882263\n",
      "Epoch 67: train loss: 0.6237176656723022\n",
      "Epoch 68: train loss: 0.6303284764289856\n",
      "Epoch 69: train loss: 0.6281219124794006\n",
      "Epoch 70: train loss: 0.6245631575584412\n",
      "Epoch 71: train loss: 0.6224830150604248\n",
      "Epoch 72: train loss: 0.6170318126678467\n",
      "Epoch 73: train loss: 0.6052889823913574\n",
      "Epoch 74: train loss: 0.6216558218002319\n",
      "Epoch 75: train loss: 0.6059960722923279\n",
      "Epoch 76: train loss: 0.6038010120391846\n",
      "Epoch 77: train loss: 0.6122339963912964\n",
      "Epoch 78: train loss: 0.6231223940849304\n",
      "Epoch 79: train loss: 0.6103439927101135\n",
      "Epoch 80: train loss: 0.6187725067138672\n",
      "Epoch 81: train loss: 0.624723494052887\n",
      "Epoch 82: train loss: 0.6261570453643799\n",
      "Epoch 83: train loss: 0.6161068677902222\n",
      "Epoch 84: train loss: 0.612273097038269\n",
      "Epoch 85: train loss: 0.5923836827278137\n",
      "Epoch 86: train loss: 0.5975573062896729\n",
      "Epoch 87: train loss: 0.6164819002151489\n",
      "Epoch 88: train loss: 0.6097369194030762\n",
      "Epoch 89: train loss: 0.6105148792266846\n",
      "Epoch 90: train loss: 0.6084610223770142\n",
      "Epoch 91: train loss: 0.6035854816436768\n",
      "Epoch 92: train loss: 0.5901747345924377\n",
      "Epoch 93: train loss: 0.6028686761856079\n",
      "Epoch 94: train loss: 0.5908126831054688\n",
      "Epoch 95: train loss: 0.5969223976135254\n",
      "Epoch 96: train loss: 0.5993488430976868\n",
      "Epoch 97: train loss: 0.5882915258407593\n",
      "Epoch 98: train loss: 0.5910778045654297\n",
      "Epoch 99: train loss: 0.6076397895812988\n",
      "Test loss  0.7286607027053833\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "model.train()\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "for epoch in range(epoch):    \n",
    "    optimizer.zero_grad()       \n",
    "    y_pred = model(x_train)       \n",
    "    loss = criterion(y_pred.squeeze(), y_train)\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    lossVal = loss.item() *1\n",
    "    if train_loss < lossVal:\n",
    "        print(\"Validation loss decreased ({:6f} ===> {:6f}). Saving the model...\".format(train_loss,lossVal))\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        train_loss = lossVal \n",
    "        \n",
    "model.eval()\n",
    "y_pred_test = model(x_test)\n",
    "after_train = criterion(y_pred_test.squeeze(), y_test) \n",
    "print('Test loss ' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Test loss before training 0.7286607027053833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model)\n",
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "before_train = criterion(y_pred.squeeze(), y_test)\n",
    "print('Test loss before training' , before_train.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
